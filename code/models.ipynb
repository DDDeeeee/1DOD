{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdea3b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import torch\n",
    "import random\n",
    "from torch import nn\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from modelscope.metainfo import Models\n",
    "from modelscope.models.builder import MODELS\n",
    "from transformers.utils import CONFIG_NAME, WEIGHTS_NAME\n",
    "from modelscope.utils.constant import ConfigFields, ModelFile\n",
    "from transformers.modeling_outputs import TokenClassifierOutput\n",
    "from modelscope.models.nlp.ponet import PoNetPreTrainedModel, PoNetModel\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0283c6d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "@MODELS.register_module(\"token-classification-task\", module_name=Models.ponet)\n",
    "class PoNetForTokenClassificationWithIOUloss(PoNetPreTrainedModel):\n",
    "    _keys_to_ignore_on_load_unexpected = [r\"pooler\"]\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.num_labels = config.num_labels\n",
    "\n",
    "        self.ponet = PoNetModel(config, add_pooling_layer=False)\n",
    "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
    "        self.classifier = nn.Linear(config.hidden_size, config.num_labels)\n",
    "        \n",
    "        self.ce_loss_coefficient=1.0\n",
    "        self.l1_loss_coefficient=0.5\n",
    "        self.iou_loss_coefficient=0.5\n",
    "        self.dice_loss_coefficient=0.5\n",
    "        self.TS_iou_dice_fct = IOU_1D()\n",
    "        self.focal_loss = FocalLoss(alpha=0.75, gamma=2, reduction='mean')\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def l1_loss_fct(self, pred, target):\n",
    "        criterion = torch.nn.L1Loss()\n",
    "        return criterion(pred, target) \n",
    "    \n",
    "    # 以下几个方法的实现与最终版本可能存在较大差别\n",
    "    # 由于代码丢失（压缩包寄了），且时间久远，我就不做修改了\n",
    "\n",
    "    def iou_loss_fct(self, pred, target):\n",
    "        iou_loss_sum = 0\n",
    "        for i in range(len(target)):\n",
    "            pred_l = pred[i].tolist()\n",
    "            target_l = target[i].tolist()\n",
    "            pred_ids = [i for i in range(len(pred_l)) if pred_l[i]==0]\n",
    "            target_ids = [i for i in range(len(target_l)) if target_l[i]==0]\n",
    "            pred_ids = [4095] if pred_ids==[] else pred_ids\n",
    "            target_ids = [4095] if target_ids==[] else target_ids\n",
    "            iou_score = self.TS_iou_dice_fct.cal_label_pred_iou_rev(target_ids, pred_ids)\n",
    "            iou_loss_sum += (1 - iou_score['weighted_iou_revavg'])\n",
    "        return torch.tensor(iou_loss_sum/len(target))\n",
    "    \n",
    "    def cal_iou_with_one_same_boundary(self,label_num, pred_num):\n",
    "        l0, l1 = label_num\n",
    "        p0, p1 = pred_num\n",
    "        iou_0 = min(p0, l0)/max(p0, l0) * l0 if p0!=0 and l0!=0 else 0\n",
    "        iou_1 = min(p1, l1)/max(p1, l1) * l1 if p1!=0 and l1!=0 else 0\n",
    "        return (iou_0+iou_1)/(l0+l1)\n",
    "\n",
    "    def cal_one_same_boundary_iou_fct(self,predication, label):\n",
    "        iou_loss_sum = 0\n",
    "        for i in range(len(predication)):\n",
    "            if 1 in predication[i]:\n",
    "                num_0 = predication[i].tolist().index(1) # 0数量\n",
    "            else:\n",
    "                num_0 = len(predication[0])\n",
    "            label_batch_list = label[i].tolist()\n",
    "            label_num_1 = label_batch_list.count(1)\n",
    "            if label_num_1 == 0:\n",
    "                label_num_0 = label_batch_list.count(0)\n",
    "            else:\n",
    "                label_num_0 = label_batch_list.index(1)\n",
    "            \n",
    "            pred_num_1 = label_num_0 + label_num_1 - num_0\n",
    "            #print(num_0, pred_num_1, label_num_0, label_num_1, cal_iou_with_one_same_boundary([label_num_0, label_num_1], [num_0, pred_num_1]))\n",
    "            iou_loss_sum += self.cal_iou_with_one_same_boundary([label_num_0, label_num_1], [num_0, pred_num_1])\n",
    "        return torch.tensor(1-iou_loss_sum/len(predication))\n",
    "    \n",
    "    def dice_loss_fct(self, pred, target):\n",
    "        dice_loss_sum = 0\n",
    "        for i in range(len(target)):\n",
    "            pred_l = pred[i].tolist()\n",
    "            target_l = target[i].tolist()\n",
    "            pred_ids = [i for i in range(len(pred_l)) if pred_l[i]==0]\n",
    "            target_ids = [i for i in range(len(target_l)) if target_l[i]==0]\n",
    "            target_ids = [4095] if target_ids==[] else target_ids\n",
    "            dice_score = self.TS_iou_dice_fct.cal_label_pred_dice(target_ids, pred_ids)\n",
    "            dice_loss_sum += (1 - 2*dice_score)\n",
    "        return torch.tensor(dice_loss_sum/len(target))\n",
    "    \n",
    "    def cal_dice_with_one_same_boundary(self, label_num, pred_num):\n",
    "        # 交集长度/(p长度+t长度)\n",
    "        smooth = 1e-6\n",
    "        l0, l1 = label_num\n",
    "        p0, p1 = pred_num\n",
    "        iou_0 = (min(p0, l0)+smooth)/(p0+l0+smooth) * l0\n",
    "        iou_1 = (min(p1, l1)+smooth)/(p1+l1+smooth) * l1\n",
    "        return (iou_0+iou_1)/(l0+l1)\n",
    "    \n",
    "    def cal_one_same_boundary_dice_fct(self,predication, label):\n",
    "        dice_loss_sum = 0\n",
    "        for i in range(len(predication)):\n",
    "            if 1 in predication[i]:\n",
    "                num_0 = predication[i].tolist().index(1) # 0数量\n",
    "            else:\n",
    "                num_0 = len(predication[0])\n",
    "            label_batch_list = label[i].tolist()\n",
    "            label_num_1 = label_batch_list.count(1)\n",
    "            if label_num_1 == 0:\n",
    "                label_num_0 = label_batch_list.count(0)\n",
    "            else:\n",
    "                label_num_0 = label_batch_list.index(1)\n",
    "            pred_num_1 = label_num_0 + label_num_1 - num_0\n",
    "            #print(num_0, pred_num_1, label_num_0, label_num_1, cal_iou_with_one_same_boundary([label_num_0, label_num_1], [num_0, pred_num_1]))\n",
    "            dice_score = self.cal_dice_with_one_same_boundary([label_num_0, label_num_1], [num_0, pred_num_1])\n",
    "            dice_loss_sum += (1 - 2*dice_score)\n",
    "        return torch.tensor(dice_loss_sum)\n",
    "        \n",
    "    def forward(\n",
    "            self,\n",
    "            #seg_type=='sent',\n",
    "            input_ids=None,\n",
    "            attention_mask=None,\n",
    "            token_type_ids=None,\n",
    "            segment_ids=None,\n",
    "            position_ids=None,\n",
    "            head_mask=None,\n",
    "            inputs_embeds=None,\n",
    "            labels=None,\n",
    "            output_attentions=None,\n",
    "            output_hidden_states=None,\n",
    "            return_dict=None,\n",
    "    ):\n",
    "        r\"\"\"\n",
    "    labels (:obj:`torch.LongTensor` of shape :obj:`(batch_size, sequence_length)`, `optional`):\n",
    "        Labels for computing the token classification loss. Indices should be in ``[0, ..., config.num_labels -\n",
    "        1]``.\n",
    "    \"\"\"\n",
    "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
    "\n",
    "        outputs = self.ponet(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "            segment_ids=segment_ids,\n",
    "            position_ids=position_ids,\n",
    "            head_mask=head_mask,\n",
    "            inputs_embeds=inputs_embeds,\n",
    "            output_attentions=output_attentions,\n",
    "            output_hidden_states=output_hidden_states,\n",
    "            return_dict=return_dict,\n",
    "        )\n",
    "\n",
    "        sequence_output = outputs[0]\n",
    "\n",
    "        sequence_output = self.dropout(sequence_output)\n",
    "        logits = self.classifier(sequence_output)\n",
    "        #predication = torch.tensor(np.argmax(logits.cpu().detach().numpy(), axis=2)).to(logits.device)\n",
    "        predication = torch.argmax(logits, -1)\n",
    "        \n",
    "\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            loss_fct = CrossEntropyLoss()\n",
    "            # Only keep active parts of the loss\n",
    "            if attention_mask is not None:\n",
    "                # 其实就是label用-100pad\n",
    "                active_loss = attention_mask.view(-1) == 1\n",
    "                active_logits = logits.view(-1, self.num_labels)\n",
    "                active_labels = torch.where(\n",
    "                    active_loss, labels.view(-1), torch.tensor(loss_fct.ignore_index).type_as(labels)\n",
    "                )\n",
    "                #ce_loss = loss_fct(active_logits, active_labels) * self.ce_loss_coefficient\n",
    "                ce_loss = self.focal_loss(active_logits, active_labels) * self.ce_loss_coefficient\n",
    "                \n",
    "            else:\n",
    "                #ce_loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1)) * self.ce_loss_coefficient\n",
    "                ce_loss = self.focal_loss(logits.view(-1, self.num_labels), labels.view(-1)) * self.ce_loss_coefficient\n",
    "            # rest loss\n",
    "            #l1_loss = self.l1_loss_fct(predication.to(torch.float32), torch.where(labels==-100,0,labels).to(torch.float32)) * self.l1_loss_coefficient\n",
    "            l1_loss = self.l1_loss_fct(predication.to(torch.float32), labels.to(torch.float32)) * self.l1_loss_coefficient\n",
    "            #iou_loss = self.iou_loss_fct(predication, labels) * self.iou_loss_coefficient\n",
    "            iou_loss = self.cal_one_same_boundary_iou_fct(predication, labels) * self.iou_loss_coefficient\n",
    "            #dice_loss = self.dice_loss_fct(predication, labels) * self.dice_loss_coefficient\n",
    "            dice_loss = self.cal_one_same_boundary_dice_fct(predication, labels) * self.dice_loss_coefficient\n",
    "            loss = ce_loss + l1_loss + iou_loss + dice_loss\n",
    "            #print(ce_loss, l1_loss, iou_loss, dice_loss)\n",
    "\n",
    "        if not return_dict:\n",
    "            output = (logits,) + outputs[2:]\n",
    "            return ((loss,) + output) if loss is not None else output\n",
    "\n",
    "        return TokenClassifierOutput(\n",
    "            loss=loss,\n",
    "            logits=logits,\n",
    "            hidden_states=outputs.hidden_states,\n",
    "            attentions=outputs.attentions,\n",
    "        )\n",
    "    \n",
    "    def save_pretrained(self, output_dir, state_dict=None):\n",
    "        output_file = os.path.join(output_dir, WEIGHTS_NAME)\n",
    "        # print(\"save state_dict to %s\" % output_file)\n",
    "        # print(\"state_dict is \", state_dict)\n",
    "        torch.save(state_dict, output_file)\n",
    "        if os.path.isfile(os.path.join(self.model_dir, CONFIG_NAME)):\n",
    "            self.config.to_json_file(os.path.join(output_dir, CONFIG_NAME))\n",
    "        if os.path.isfile(os.path.join(self.model_dir, ModelFile.CONFIGURATION)):\n",
    "            shutil.copy(os.path.join(self.model_dir, ModelFile.CONFIGURATION), os.path.join(output_dir, ModelFile.CONFIGURATION))\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
